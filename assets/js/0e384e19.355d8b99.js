"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[671],{2445:(e,s,i)=>{i.r(s),i.d(s,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>d});var n=i(5893),r=i(1151);const t={title:"Introduction",sidebar_position:1},a=void 0,o={id:"intro",title:"Introduction",description:"This repository contains a collection of Jupyter Notebooks that demonstrate how to use the Responsible AI Toolbox to build Responsible AI solutions.",source:"@site/docs/intro.md",sourceDirName:".",slug:"/intro",permalink:"/responsible-ai/docs/intro",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Introduction",sidebar_position:1},sidebar:"concepts",next:{title:"Introduction",permalink:"/responsible-ai/docs/core-concepts/introduction"}},l={},d=[{value:"1. What is Responsible AI?",id:"1-what-is-responsible-ai",level:2},{value:"2. What is the Responsible AI Toolbox?",id:"2-what-is-the-responsible-ai-toolbox",level:2},{value:"3. Responsible AI Dashboard Components",id:"3-responsible-ai-dashboard-components",level:2},{value:"3.1 Error Analysis Dashboard",id:"31-error-analysis-dashboard",level:3},{value:"3.2 Explanation Dashboard",id:"32-explanation-dashboard",level:3},{value:"3.3 Fairness Dashboard",id:"33-fairness-dashboard",level:3},{value:"3.4 Responsible AI Dashboard",id:"34-responsible-ai-dashboard",level:3},{value:"4. Responsible AI Dashboard Usage",id:"4-responsible-ai-dashboard-usage",level:2},{value:"4.1 The OSS  <code>raiwidgets</code> Python Package",id:"41-the-oss--raiwidgets-python-package",level:3},{value:"4.2 The Azure ML Responsible AI Dashboard",id:"42-the-azure-ml-responsible-ai-dashboard",level:3},{value:"4. Responsible AI Dashboard Notebooks",id:"4-responsible-ai-dashboard-notebooks",level:2}];function c(e){const s={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(s.p,{children:"This repository contains a collection of Jupyter Notebooks that demonstrate how to use the Responsible AI Toolbox to build Responsible AI solutions."}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:["Notebooks here are reproduced from the ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks",children:"Responsible AI Toolnox: Notebook Tutorials"})," for learning purposes only."]}),"\n",(0,n.jsxs)(s.li,{children:["Read ",(0,n.jsx)(s.a,{href:"https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/responsible-ai-dashboard-and-scorecard-in-azure-machine-learning/ba-p/3391068",children:"this May 2022 Technical Community Blog Post"})," for a comprehensive overview of the Responsible AI Toolbox."]}),"\n"]}),"\n",(0,n.jsx)(s.h2,{id:"1-what-is-responsible-ai",children:"1. What is Responsible AI?"}),"\n",(0,n.jsx)(s.p,{children:"Responsible Artificial Intelligence (Responsible AI) is an approach to developing, assessing, and deploying AI systems in a safe, trustworthy, and ethical way."}),"\n",(0,n.jsxs)(s.p,{children:["Microsoft has developed a ",(0,n.jsx)(s.a,{href:"https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf",children:"Responsible AI Standard (Jun 2022)"}),". It's a framework for building AI systems according to six principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability."]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://learn.microsoft.com/en-us/azure/machine-learning/media/concept-responsible-ai/concept-responsible-ml.png?view=azureml-api-2",alt:"Responsible AI Standards"})}),"\n",(0,n.jsx)(s.p,{children:'The principles are summarized briefly below, with links to relevant documentation and "assessment" components from the toolbox that help validate compliance.'}),"\n",(0,n.jsxs)(s.table,{children:[(0,n.jsx)(s.thead,{children:(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.th,{children:"Principle"}),(0,n.jsx)(s.th,{children:"Description"}),(0,n.jsx)(s.th,{children:"Assessment"})]})}),(0,n.jsxs)(s.tbody,{children:[(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2#fairness-and-inclusiveness",children:"Fairness and Inclusiveness"})}),(0,n.jsxs)(s.td,{children:["AI systems should treat everyone fairly and avoid affecting similarly situated groups of people in different ways. ",(0,n.jsx)("br",{}),(0,n.jsx)(s.em,{children:"Ex: All loan applicants with similar backgrounds should get the same recommendations or outcomes."})]}),(0,n.jsxs)(s.td,{children:["RAI Dashboard - ",(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-fairness-ml?view=azureml-api-2",children:"Fairness Assessment"})]})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2#reliability-and-safety",children:"Reliability and Safety"})}),(0,n.jsx)(s.td,{children:"To build trust, it's critical that AI systems operate as they were originally designed, respond safely to unanticipated conditions, and resist harmful manipulation."}),(0,n.jsxs)(s.td,{children:["RAI Dashboard - ",(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-error-analysis?view=azureml-api-2",children:"Error Analysis"})]})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2#transparency",children:"Transparency"})}),(0,n.jsxs)(s.td,{children:["When AI systems influence decisions that impact people's lives, it's critical that people understand how those decisions were made. A crucial part of transparency is ",(0,n.jsx)(s.strong,{children:"interpretability"}),": the useful explanation of the behavior of AI systems and their components"]}),(0,n.jsxs)(s.td,{children:["RAI Dashboard - ",(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability?view=azureml-api-2",children:"Interpretability"})," ",(0,n.jsx)("br",{}),(0,n.jsx)("br",{})," RAI Dashboard -  ",(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-counterfactual-analysis?view=azureml-api-2",children:"Counterfacutal What-If"})]})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2#privacy-and-security",children:"Privacy and Security"})}),(0,n.jsx)(s.td,{children:"With AI, privacy and data security require close attention because access to data is essential for AI systems to make accurate and informed predictions and decisions about people. AI systems must comply with privacy laws on data usage transparency & consumer control over usage."}),(0,n.jsxs)(s.td,{children:[(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-enterprise-security?view=azureml-api-2",children:"Azure ML Governance"})," support ",(0,n.jsx)("br",{}),(0,n.jsx)("br",{})," ",(0,n.jsx)(s.a,{href:"https://github.com/opendifferentialprivacy/smartnoise-core",children:"SmartNoise"})," OSS to build differential privacy solutions",(0,n.jsx)("br",{})," ",(0,n.jsx)("br",{})," ",(0,n.jsx)(s.a,{href:"https://github.com/Azure/counterfit/",children:"Counterfit"})," OSS cyberattack simulator"]})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Inclusiveness"}),(0,n.jsx)(s.td,{children:"AI systems should be inclusive and accessible."}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Accountability"}),(0,n.jsx)(s.td,{children:"AI systems should be accountable."}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{})]})]})]}),"\n",(0,n.jsxs)(s.p,{children:["See: ",(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2",children:"What is Responsible AI"})]}),"\n",(0,n.jsx)(s.h2,{id:"2-what-is-the-responsible-ai-toolbox",children:"2. What is the Responsible AI Toolbox?"}),"\n",(0,n.jsxs)(s.p,{children:["It's an ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox",children:"open-source project"})," that provides tools and guidance to help AI practitioners apply ",(0,n.jsx)(s.em,{children:"responsible AI principles and practices"})," to their work with components and dashboards to help them ",(0,n.jsx)(s.em,{children:"design and assess"})," their models and decision-making workflows for compliance."]}),"\n",(0,n.jsxs)(s.p,{children:["The core of the toolbox is the ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox?tab=readme-ov-file#introducing-responsible-ai-dashboard",children:"Responsible AI Dashboard"})," that is a ",(0,n.jsx)(s.em,{children:"single pane of glass"})," to help you flow through the different stages of ",(0,n.jsx)(s.strong,{children:"model development & debugging"})," to ",(0,n.jsx)(s.strong,{children:"decision-making & deployment"}),'. In this context, "single pane of glass" means a ',(0,n.jsx)(s.strong,{children:"unified display"})," that integrates and displays information from multiple sources in a single view, for convenience and context."]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://raw.githubusercontent.com/microsoft/responsible-ai-widgets/main/img/responsible-ai-dashboard.png",alt:"Responsible AI Dashboard"})}),"\n",(0,n.jsxs)(s.p,{children:["You can use this toolkit to understand your model's behavior, identify and mitigate bias, and explain your model's predictions. You can also use it to ",(0,n.jsx)(s.em,{children:"perturb"})," model predictions for individual instances, and use that to gain better insight into responsible AI compliance."]}),"\n",(0,n.jsx)(s.p,{children:"The Responsible AI Dashboard integrates several open-source toolkits into a unified platform for developers and data scientists."}),"\n",(0,n.jsxs)(s.table,{children:[(0,n.jsx)(s.thead,{children:(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.th,{children:"Toolkit"}),(0,n.jsx)(s.th,{children:"Description"})]})}),(0,n.jsxs)(s.tbody,{children:[(0,n.jsxs)(s.tr,{children:[(0,n.jsxs)(s.td,{children:["Fairness Assessment with ",(0,n.jsx)(s.a,{href:"https://github.com/fairlearn/fairlearn",children:"Fairlearn"})]}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.em,{children:"identifies cohorts of data with higher error rate than the overall benchmark"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsxs)(s.td,{children:["Error Analysis with ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-widgets/blob/main/docs/erroranalysis-dashboard-README.md",children:"Error Analysis Tool"})]}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.em,{children:"identifies which groups may be disproportionately negatively impacted by AI & how."})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsxs)(s.td,{children:["Interpretability with ",(0,n.jsx)(s.a,{href:"https://github.com/interpretml/interpret-community",children:"InterpretML"})]}),(0,n.jsx)(s.td,{children:"_explains blackbox models, helping users understand the reasons behind  predictions."})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsxs)(s.td,{children:["Counterfactual Analysis with ",(0,n.jsx)(s.a,{href:"https://github.com/interpretml/DiCE",children:"DiCE"})]}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.em,{children:"shows if/how feature-perturbed versions of same data give different prediction"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsxs)(s.td,{children:["Causal Analysis with ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/EconML",children:"EconML"})]}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.em,{children:"focuses on answering What If-style questions to apply data-driven decision-making"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsxs)(s.td,{children:["Data Balance with ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox/blob/main/docs/databalance-README.md",children:"Responsible AI"})]}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.em,{children:"helps users gain an overall understanding of their data, visualize feature distribution"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{})]})]})]}),"\n",(0,n.jsx)(s.h2,{id:"3-responsible-ai-dashboard-components",children:"3. Responsible AI Dashboard Components"}),"\n",(0,n.jsx)(s.p,{children:"The toolbox consists of 4 core dashboards as shown below:"}),"\n",(0,n.jsx)(s.h3,{id:"31-error-analysis-dashboard",children:"3.1 Error Analysis Dashboard"}),"\n",(0,n.jsx)(s.p,{children:"The Error Explorer Dashboard lets you identify cohors with higher error rates, and diagnose root causes behind these errors. Once you load this dashboard, you can explore your model in 2 stages:"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Identification"}),' of errors - using the decision tree ("Treemap") or the distribution ("Heatmap") view.']}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Diagnosis"})," of errors - by saving cohorts of interest, then exploring them in more detail (e.g., dataset stats & feature distributions) or conducting what-if experiments (perturbation exploration)."]}),"\n"]}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://github.com/microsoft/responsible-ai-toolbox/raw/main/docs/img/EA-TreeMap.png",alt:"Error Explorer"})}),"\n",(0,n.jsx)(s.h3,{id:"32-explanation-dashboard",children:"3.2 Explanation Dashboard"}),"\n",(0,n.jsxs)(s.p,{children:["This is the interface for ",(0,n.jsx)(s.a,{href:"https://github.com/interpretml/interpret-community",children:"Interpret-Community"})," which provides SDK and notebooks with intepretabilty utility functions and techniques developed by the community at large."]}),"\n",(0,n.jsx)(s.p,{children:"Use this dashboard to evaluate your model, explore your dataset statistics, understanding your model's explanations for various demographics, and debug models by trying perturbations (what-if analysis) to gain insights into your model's behavior."}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://github.com/microsoft/responsible-ai-toolbox/raw/main/docs/img/Interpretability-ModelPerformance.png",alt:"Explanation Dashboard"})}),"\n",(0,n.jsx)(s.p,{children:"The explanation dashboard has 4 tabs as shown:"}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Model performance tab - helps observe performance of your model across different cohorts"}),"\n",(0,n.jsx)(s.li,{children:"Dataset explorer - helps explore dataset by slicing it up by different dimensions for comparisons."}),"\n",(0,n.jsx)(s.li,{children:"Aggregate feature importance (global explanation) - helps understand which features are most important for your model's predictions (and how feature impacts predictions)."}),"\n",(0,n.jsx)(s.li,{children:"Individual feature importance and what-if (local explanation) - helps understand how feature values impact predictions for an individual instance."}),"\n"]}),"\n",(0,n.jsx)(s.h3,{id:"33-fairness-dashboard",children:"3.3 Fairness Dashboard"}),"\n",(0,n.jsx)(s.p,{children:"The Fairness dashboard enables you to use common fairness metrics to assess which groups of people may be negatively impacted by your machine learning model's prediction (females vs. males vs. non-binary gender). You can then use Fairlearn's state-of-the-art unfairness mitigation algorithms to mitigate fairness issues in your classification and regression models."}),"\n",(0,n.jsx)(s.p,{children:(0,n.jsx)(s.img,{src:"https://github.com/microsoft/responsible-ai-toolbox/raw/main/docs/img/Fairness-Intro.png",alt:"Fairness Dashboard"})}),"\n",(0,n.jsx)(s.h3,{id:"34-responsible-ai-dashboard",children:"3.4 Responsible AI Dashboard"}),"\n",(0,n.jsxs)(s.p,{children:["The Responsible AI Dashboard is the ",(0,n.jsx)(s.em,{children:"unified pane of glass"})," that empowers users to design tailored, end-to-end model debugging and decision-making workflows that address their particular needs."]}),"\n",(0,n.jsxs)(s.p,{children:[(0,n.jsx)(s.strong,{children:"It's key strength lies in customizability"})," you put together subsets of components in a way that helps you analyze your model's behavior for different scenarios, in different ways."]}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:["Below are some examples of use case and workflow thinking - see ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox/?tab=readme-ov-file#responsible-ai-dashboard-customization",children:"this document"})," for the full list."]}),"\n"]}),"\n",(0,n.jsxs)(s.table,{children:[(0,n.jsx)(s.thead,{children:(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.th,{children:(0,n.jsx)(s.em,{children:"I want to ..."})}),(0,n.jsx)(s.th,{children:"RAI Dashboard Flow"})]})}),(0,n.jsxs)(s.tbody,{children:[(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"understand model errors & diagnose them"}),(0,n.jsx)(s.td,{children:"Model Overview \u27a1\ufe0f Error Analysis \u27a1\ufe0f Data Explorer"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"understand model fairness issues & diagnost them"}),(0,n.jsx)(s.td,{children:"Model Overview \u27a1\ufe0f Fairness Assessment \u27a1\ufe0f Data Explorer"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"address customer questions about what they can do differently next time to get a different outcome from AI"}),(0,n.jsx)(s.td,{children:"Data Explorer \u27a1\ufe0f Counterfactuals Analysis and What-If"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{})]})]})]}),"\n",(0,n.jsx)(s.h2,{id:"4-responsible-ai-dashboard-usage",children:"4. Responsible AI Dashboard Usage"}),"\n",(0,n.jsxs)(s.p,{children:["The ",(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox/?tab=readme-ov-file#responsible-ai-dashboard-customization",children:"Responsible AI Toolbox"})," exists as an open-source project driven by Microsoft Research, and usable as a Python package for research and learning purposes."]}),"\n",(0,n.jsx)(s.p,{children:'However, usage by enterprise customers requires both a seamless integration into their end-to-end workflows, and support for features that are critical to regulatory and business processes. With that in mind, here are the two "flavors" of Responsible AI Dashboard today.'}),"\n",(0,n.jsxs)(s.h3,{id:"41-the-oss--raiwidgets-python-package",children:["4.1 The OSS  ",(0,n.jsx)(s.code,{children:"raiwidgets"})," Python Package"]}),"\n",(0,n.jsx)(s.p,{children:"If you are looking to understand the core concepts, and explore the capabilities of the Responsible AI Toolbox, you can use the Responsible AI Notebook Tutorials listed below."}),"\n",(0,n.jsxs)(s.p,{children:["These use the ",(0,n.jsx)(s.code,{children:"raiwidgets"})," Python package (currently v0.32.1 - released Dec 6, 2023) - which  contains the core widgets used for ",(0,n.jsx)(s.em,{children:"interactive visualizations"})," to assess fairness, explain models, generate counterfactual examples, analyze causal effects and analyze errors in Machine Learning models."]}),"\n",(0,n.jsxs)(s.p,{children:["This is an open-source option for interactively visualizing the dashboard components with your data sets and models, ",(0,n.jsx)(s.em,{children:"in your local development environment"}),". It's a good way to get familiar with the concepts, and explore the various capabilities and features interactively - in an environment like GitHub Codespaces, for convenience."]}),"\n",(0,n.jsx)(s.h3,{id:"42-the-azure-ml-responsible-ai-dashboard",children:"4.2 The Azure ML Responsible AI Dashboard"}),"\n",(0,n.jsxs)(s.p,{children:["While the Responsible AI Toolbox exists as an open-source project, it is also ",(0,n.jsx)(s.a,{href:"https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/responsible-ai-dashboard-and-scorecard-in-azure-machine-learning/ba-p/3391068",children:"integrated into the Azure Machine Learning Service"})," as of Nov 2022, to simplify integration and usage with ",(0,n.jsx)(s.em,{children:"cloud-deployed models"}),". Using this integration, you can now generate Responsible AI Dashboards for your models using:"]}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.a,{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-insights-ui?view=azureml-api-2",children:"Azure Machine Learning Studio"})," - no code option"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.a,{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-insights-sdk-cli?view=azureml-api-2&tabs=yaml",children:"Azure Machine Learning Python SDK"})," - code-first option"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.a,{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-insights-sdk-cli?view=azureml-api-2&tabs=yaml",children:"Azure Machine Learning CLI"})," - commandline option"]}),"\n"]}),"\n",(0,n.jsxs)(s.p,{children:["These are the key tools accessible via the Responsible AI Dashboard in the Azure Machine Learning service:\n",(0,n.jsx)(s.img,{src:"https://learn.microsoft.com/azure/machine-learning/media/concept-responsible-ai-dashboard/dashboard.png?view=azureml-api-2",alt:"Azure ML Responsible AI Dashboard"})]}),"\n",(0,n.jsx)(s.p,{children:"And while the initial examples focused on tabular data that is available in a tabular format (e.g., CSV, Parquet, etc.) we can also use the Responsible AI Dashboard (on Azure ML) to assess the performance, fairness and explainability of computer vision and natural language processing models."}),"\n",(0,n.jsxs)(s.ol,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-vision-insights?view=azureml-api-2&tabs=yaml",children:"Generate Responsible AI Vision Insights"})," - for computer vision models (image classification, object detection, etc.)"]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-text-insights?view=azureml-api-2&tabs=yaml",children:"Generate Responsible AI Text Insights"})," - for NLP models (multi-label text classification, etc.)"]}),"\n"]}),"\n",(0,n.jsxs)(s.p,{children:["The Azure ML integration also supports the ability to generate ",(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/azure/machine-learning/concept-responsible-ai-scorecard?view=azureml-api-2",children:"Responsible AI Scorecards"})," ",(0,n.jsx)(s.em,{children:"which are critical to regulatory and business processes"})," that enterprise customers need to comply with.  The Responsible AI Scorecard lets ML professionals ",(0,n.jsx)(s.em,{children:"generate and share"})," their data and model health records with stakeholders to earn trust or for auditing purposes."]}),"\n",(0,n.jsxs)(s.ol,{children:["\n",(0,n.jsx)(s.li,{children:(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/azure/machine-learning/how-to-responsible-ai-insights-sdk-cli?view=azureml-api-2&tabs=yaml#how-to-generate-a-responsible-ai-scorecard-preview",children:"Generate a Responsible AI Scorecard using the SDK/CLI"})}),"\n",(0,n.jsx)(s.li,{children:(0,n.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-insights-ui?view=azureml-api-2#how-to-generate-responsible-ai-scorecard-preview",children:"Generate a Responsible AI Scorecard using the UI"})}),"\n"]}),"\n",(0,n.jsxs)(s.p,{children:["Want to explore these features further? Check out the ",(0,n.jsx)(s.a,{href:"https://github.com/Azure/azureml-examples/tree/main/sdk/python/responsible-ai",children:"Azure Machine Learning Responsible AI Dashboard & Scorecard"})," repo for a list of Notebooks-based tutorials. You will need an active Azure account (and subscription) to do so."]}),"\n",(0,n.jsx)(s.h2,{id:"4-responsible-ai-dashboard-notebooks",children:"4. Responsible AI Dashboard Notebooks"}),"\n",(0,n.jsx)(s.p,{children:"We can structure our learning journey with Jupyter Notebooks into 3 phases:"}),"\n",(0,n.jsxs)(s.ol,{children:["\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Introduction"})," - Notebooks that explain the concepts and capabilities of the Responsible AI Toolbox without necessarily running any code snippets."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"RAI Toolbox"})," - Notebooks that demonstrate how to use the Responsible AI Toolbox with the ",(0,n.jsx)(s.code,{children:"raiwidgets"})," Python package in Jupyter Notebooks, on GitHub Codesapces."]}),"\n",(0,n.jsxs)(s.li,{children:[(0,n.jsx)(s.strong,{children:"Azure ML"})," - Notebooks that demonstrate how to use the Responsible AI Toolbox with the Azure ML Service - using the Studio UI, Python SDK and/or CLI."]}),"\n"]}),"\n",(0,n.jsx)(s.p,{children:'In the table below, the "Type" of notebook defines the kind of data and model being analyzed:'}),"\n",(0,n.jsxs)(s.ul,{children:["\n",(0,n.jsx)(s.li,{children:"Tabular = CSV or Parquet datasets"}),"\n",(0,n.jsx)(s.li,{children:"Vision = Image classification or object detection models"}),"\n",(0,n.jsx)(s.li,{children:"Text = Text classification or NLP models"}),"\n"]}),"\n",(0,n.jsxs)(s.table,{children:[(0,n.jsx)(s.thead,{children:(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.th,{children:"Notebook"}),(0,n.jsx)(s.th,{children:"Type"}),(0,n.jsx)(s.th,{children:"Description"})]})}),(0,n.jsxs)(s.tbody,{children:[(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:"Introduction"})}),(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{target:"_blank",href:i(1138).Z+"",children:"Responsible AI Toolbox"})}),(0,n.jsx)(s.td,{children:"-"}),(0,n.jsx)(s.td,{children:"Tour of the RAI Toolbox as documentation (no code)"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{target:"_blank",href:i(9937).Z+"",children:"Getting Started"})}),(0,n.jsx)(s.td,{children:"-"}),(0,n.jsx)(s.td,{children:"Explains high-level APIs and workflows (setup validation)"})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:(0,n.jsx)(s.a,{href:"https://github.com/microsoft/responsible-ai-toolbox?tab=readme-ov-file#useful-links",children:"RAI Toolbox"})})}),(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{target:"_blank",href:i(3858).Z+"",children:"Census Classification Model Debugging"})}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{target:"_blank",href:i(3140).Z+"",children:"Diabetes Decision Making "})}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{target:"_blank",href:i(3514).Z+"",children:"Diabetes Regression Model Debugging"})}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Housing Classification Model"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Housing Decision Making"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Multiclass DNN Model Debugging"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Orange Juice Forecasting"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Hugging Face BLBooks Genre Text Classification"}),(0,n.jsx)(s.td,{children:"Text"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Covid Event Multilabel Text Classification Model Debugging"}),(0,n.jsx)(s.td,{children:"Text"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"DBPedia Text Classification Model Debugging"}),(0,n.jsx)(s.td,{children:"Text"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"OpenAI Model Debugging"}),(0,n.jsx)(s.td,{children:"Text"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Question-Answering Model Debugging"}),(0,n.jsx)(s.td,{children:"Text"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Fridge Image Classification Model Debugging"}),(0,n.jsx)(s.td,{children:"Vision"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Fridge Multi-label Image Classification Model Debugging)"}),(0,n.jsx)(s.td,{children:"Vision"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Fridge Object Detection Model Debugging"}),(0,n.jsx)(s.td,{children:"Vision"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Cognitive Services: Speech-to-Text Fairness Testing"}),(0,n.jsx)(s.td,{children:"Cognitive Services"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Cognitive Services: Face Verification Fairness Testing"}),(0,n.jsx)(s.td,{children:"Cognitive Services"}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:(0,n.jsx)(s.strong,{children:(0,n.jsx)(s.a,{href:"https://github.com/Azure/azureml-examples/tree/main/sdk/python/responsible-ai",children:"Azure ML"})})}),(0,n.jsx)(s.td,{}),(0,n.jsx)(s.td,{})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Diabetes Regression Model Debugging"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html",children:"sklearn dataset"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Programmer Regression Model Debugging"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://github.com/Azure/azureml-examples/blob/main/sdk/python/responsible-ai/tabular/responsibleaidashboard-programmer-regression-model-debugging/data-programmer-regression",children:"Programmers MLTable dataset"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Finance Loan Classification"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://github.com/Azure/azureml-examples/blob/main/sdk/python/responsible-ai/tabular/responsibleaidashboard-finance-loan-classification/Fabricated_Loan_data.csv",children:"Finance Story dataset"})})]}),(0,n.jsxs)(s.tr,{children:[(0,n.jsx)(s.td,{children:"Covid Healthcare Classification"}),(0,n.jsx)(s.td,{children:"Tabular"}),(0,n.jsx)(s.td,{children:(0,n.jsx)(s.a,{href:"https://github.com/Azure/azureml-examples/blob/main/sdk/python/responsible-ai/tabular/responsibleaidashboard-healthcare-covid-classification/data_covid_classification",children:"Healthcare Story dataset"})})]})]})]})]})}function h(e={}){const{wrapper:s}={...(0,r.a)(),...e.components};return s?(0,n.jsx)(s,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},1138:(e,s,i)=>{i.d(s,{Z:()=>n});const n=i.p+"assets/files/01-tour-14ffdf5ab9f6f013ed1788aff6c93894.ipynb"},9937:(e,s,i)=>{i.d(s,{Z:()=>n});const n=i.p+"assets/files/02-getting-started-ecf8b5d3574f0b035eae787ae2913645.ipynb"},3858:(e,s,i)=>{i.d(s,{Z:()=>n});const n=i.p+"assets/files/03-rai-model-debugging-census-classification-8cda12510d2455c0fe3c9091dc0e1812.ipynb"},3140:(e,s,i)=>{i.d(s,{Z:()=>n});const n=i.p+"assets/files/04-rai-model-debugging-diabetes-regression-71139e6c192e5284829692a304aeefa3.ipynb"},3514:(e,s,i)=>{i.d(s,{Z:()=>n});const n=i.p+"assets/files/05-rai-decision-making-diabetes-regression-9beaba29178188ef36aa8c219574a394.ipynb"},1151:(e,s,i)=>{i.d(s,{Z:()=>o,a:()=>a});var n=i(7294);const r={},t=n.createContext(r);function a(e){const s=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(t.Provider,{value:s},e.children)}}}]);